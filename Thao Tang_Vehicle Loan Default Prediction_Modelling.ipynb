{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da90314b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "####### XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "####### Neural network \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc1557",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "* [Data Dictionary](#datadic)\n",
    "* [Define preprocessing steps](#preprocessing)\n",
    "* [Modeling](#model)\n",
    "    * [1. Logistic Regression](#logit)\n",
    "    * [2. Neural Network](#nn)\n",
    "    * [3. XGBoost](#xgb)\n",
    "    * [4. Random Forest](#rf)\n",
    "* [Model evaluation](#eva)\n",
    "* [Adjusting threshold](#threshold)\n",
    "* [Feature Selection](#fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8f8ab",
   "metadata": {},
   "source": [
    "# Data Dictionary <a class=\"anchor\" id=\"datadic\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9970d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import option_context\n",
    "data_dic=pd.read_csv('Data_dictionary.csv',index_col=0 ,keep_default_na=False)\n",
    "data_dic.columns = ['Description','']\n",
    "with option_context('display.max_colwidth',400):\n",
    "    display(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3cfb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv('X_train_NEWWWW.csv',index_col=0)\n",
    "X_test=pd.read_csv('X_test_NEWWWW.csv',index_col=0)\n",
    "y_train=pd.read_csv('y_train.csv')\n",
    "y_test=pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebb06559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISBURSED_AMOUNT</th>\n",
       "      <th>ASSET_COST</th>\n",
       "      <th>LTV</th>\n",
       "      <th>BRANCH_ID</th>\n",
       "      <th>SUPPLIER_ID</th>\n",
       "      <th>MANUFACTURER_ID</th>\n",
       "      <th>CURRENT_PINCODE_ID</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>STATE_ID</th>\n",
       "      <th>EMPLOYEE_CODE_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>PRIMARY_INSTAL_AMT</th>\n",
       "      <th>SEC_INSTAL_AMT</th>\n",
       "      <th>NEW_ACCTS_IN_LAST_SIX_MONTHS</th>\n",
       "      <th>DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS</th>\n",
       "      <th>AVERAGE_ACCT_AGE</th>\n",
       "      <th>CREDIT_HISTORY_LENGTH</th>\n",
       "      <th>NO_OF_INQUIRIES</th>\n",
       "      <th>DISBURSAL_MONTH</th>\n",
       "      <th>DISBURSAL_DAY</th>\n",
       "      <th>AGE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUEID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502118</th>\n",
       "      <td>48849</td>\n",
       "      <td>67000</td>\n",
       "      <td>73.88</td>\n",
       "      <td>68</td>\n",
       "      <td>18332</td>\n",
       "      <td>86</td>\n",
       "      <td>854</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>6</td>\n",
       "      <td>626</td>\n",
       "      <td>...</td>\n",
       "      <td>8319</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508189</th>\n",
       "      <td>33341</td>\n",
       "      <td>89163</td>\n",
       "      <td>39.25</td>\n",
       "      <td>65</td>\n",
       "      <td>16166</td>\n",
       "      <td>48</td>\n",
       "      <td>6852</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>13</td>\n",
       "      <td>2414</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555903</th>\n",
       "      <td>55259</td>\n",
       "      <td>72900</td>\n",
       "      <td>76.82</td>\n",
       "      <td>2</td>\n",
       "      <td>23351</td>\n",
       "      <td>86</td>\n",
       "      <td>2382</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          DISBURSED_AMOUNT  ASSET_COST    LTV  BRANCH_ID  SUPPLIER_ID  \\\n",
       "UNIQUEID                                                                \n",
       "502118               48849       67000  73.88         68        18332   \n",
       "508189               33341       89163  39.25         65        16166   \n",
       "555903               55259       72900  76.82          2        23351   \n",
       "\n",
       "          MANUFACTURER_ID  CURRENT_PINCODE_ID EMPLOYMENT_TYPE  STATE_ID  \\\n",
       "UNIQUEID                                                                  \n",
       "502118                 86                 854        Salaried         6   \n",
       "508189                 48                6852   Self employed        13   \n",
       "555903                 86                2382        Salaried         4   \n",
       "\n",
       "          EMPLOYEE_CODE_ID  ...  PRIMARY_INSTAL_AMT  SEC_INSTAL_AMT  \\\n",
       "UNIQUEID                    ...                                       \n",
       "502118                 626  ...                8319               0   \n",
       "508189                2414  ...                   0               0   \n",
       "555903                  24  ...                1999               0   \n",
       "\n",
       "          NEW_ACCTS_IN_LAST_SIX_MONTHS  DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS  \\\n",
       "UNIQUEID                                                                      \n",
       "502118                               2                                    0   \n",
       "508189                               0                                    0   \n",
       "555903                               1                                    0   \n",
       "\n",
       "          AVERAGE_ACCT_AGE  CREDIT_HISTORY_LENGTH NO_OF_INQUIRIES  \\\n",
       "UNIQUEID                                                            \n",
       "502118                   3                      7               2   \n",
       "508189                   0                      0               0   \n",
       "555903                  12                     19               0   \n",
       "\n",
       "          DISBURSAL_MONTH  DISBURSAL_DAY  AGE  \n",
       "UNIQUEID                                       \n",
       "502118                 12              9   26  \n",
       "508189                  9             15   33  \n",
       "555903                  3             10   30  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2312ad9",
   "metadata": {},
   "source": [
    "### Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "914b276b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>PERFORM_CNS_SCORE_DESCRIPTION</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNIQUEID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>502118</th>\n",
       "      <td>Salaried</td>\n",
       "      <td>F-Low Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508189</th>\n",
       "      <td>Self employed</td>\n",
       "      <td>No Bureau History Available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555903</th>\n",
       "      <td>Salaried</td>\n",
       "      <td>B-Very Low Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         EMPLOYMENT_TYPE PERFORM_CNS_SCORE_DESCRIPTION\n",
       "UNIQUEID                                              \n",
       "502118          Salaried                    F-Low Risk\n",
       "508189     Self employed   No Bureau History Available\n",
       "555903          Salaried               B-Very Low Risk"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['EMPLOYMENT_TYPE','PERFORM_CNS_SCORE_DESCRIPTION']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a6ee2f",
   "metadata": {},
   "source": [
    "### Numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537cf4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DISBURSED_AMOUNT',\n",
       " 'ASSET_COST',\n",
       " 'LTV',\n",
       " 'BRANCH_ID',\n",
       " 'SUPPLIER_ID',\n",
       " 'MANUFACTURER_ID',\n",
       " 'CURRENT_PINCODE_ID',\n",
       " 'STATE_ID',\n",
       " 'EMPLOYEE_CODE_ID',\n",
       " 'AADHAR_FLAG',\n",
       " 'PAN_FLAG',\n",
       " 'VOTERID_FLAG',\n",
       " 'DRIVING_FLAG',\n",
       " 'PASSPORT_FLAG',\n",
       " 'PERFORM_CNS_SCORE',\n",
       " 'PRI_NO_OF_ACCTS',\n",
       " 'PRI_ACTIVE_ACCTS',\n",
       " 'PRI_OVERDUE_ACCTS',\n",
       " 'PRI_CURRENT_BALANCE',\n",
       " 'PRI_SANCTIONED_AMOUNT',\n",
       " 'PRI_DISBURSED_AMOUNT',\n",
       " 'SEC_NO_OF_ACCTS',\n",
       " 'SEC_ACTIVE_ACCTS',\n",
       " 'SEC_OVERDUE_ACCTS',\n",
       " 'SEC_CURRENT_BALANCE',\n",
       " 'SEC_SANCTIONED_AMOUNT',\n",
       " 'SEC_DISBURSED_AMOUNT',\n",
       " 'PRIMARY_INSTAL_AMT',\n",
       " 'SEC_INSTAL_AMT',\n",
       " 'NEW_ACCTS_IN_LAST_SIX_MONTHS',\n",
       " 'DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS',\n",
       " 'AVERAGE_ACCT_AGE',\n",
       " 'CREDIT_HISTORY_LENGTH',\n",
       " 'NO_OF_INQUIRIES',\n",
       " 'DISBURSAL_MONTH',\n",
       " 'DISBURSAL_DAY',\n",
       " 'AGE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col=X_train.select_dtypes(include='number').columns.tolist()\n",
    "num_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978ff3f7",
   "metadata": {},
   "source": [
    "# Define preprocessing steps <a class=\"anchor\" id=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce5080e",
   "metadata": {},
   "source": [
    "In preprocessing, we would do **OneHotEncoding** for `'EMPLOYMENT_TYPE` and `PERFORM_CNS_SCORE_DESCRIPTION`, and **StandardScaling** the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96191b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['EMPLOYMENT_TYPE','PERFORM_CNS_SCORE_DESCRIPTION']\n",
    "numeric_features = num_col\n",
    "\n",
    "ohe = Pipeline(steps=[(\"encoder\", OneHotEncoder(drop = 'first'))])\n",
    "\n",
    "scale = Pipeline(steps=[(\"scaler\", StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[(\"ohe\", ohe, categorical_features),\n",
    "                  (\"scale\", scale, numeric_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d4a7c6",
   "metadata": {},
   "source": [
    "# Modeling  <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a197fa8",
   "metadata": {},
   "source": [
    "## 1. Logistic regression  <a class=\"anchor\" id=\"logit\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1689037",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079b6363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(\n",
    "    steps=[(\"preprocessor\", preprocessor),\\\n",
    "           (\"classifier\", LogisticRegression(random_state=17, max_iter=1000))])\n",
    "\n",
    "param_grid = {'classifier__C': [0.0001,0.001,0.01,0.1]}\n",
    "\n",
    "logit = GridSearchCV(pipe, param_grid, n_jobs = -1, verbose=3, return_train_score=True)\n",
    "logit_fitted =logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6400f2b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__C': 0.0001}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best param\n",
    "logit_fitted.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25a2aecb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7827409716066679"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best validation score\n",
    "logit_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74f8c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.783\n",
      "Test accuracy: 0.783\n",
      "Accuracy difference: -0.0001\n"
     ]
    }
   ],
   "source": [
    "# score\n",
    "print(\"Train accuracy: %.3f\" % logit_fitted.score(X_train, y_train))\n",
    "print(\"Test accuracy: %.3f\" % logit_fitted.score(X_test, y_test))\n",
    "print(f'Accuracy difference: {(logit_fitted.score(X_train, y_train)-logit_fitted.score(X_test, y_test)).round(4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc80e3f",
   "metadata": {},
   "source": [
    "The accuracies are not bad and close to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b5ee4",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd23ca9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# look at confusion matrix\n",
    "ConfusionMatrixDisplay.from_estimator(logit_fitted, X_test, y_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53f2d0cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     45636\n",
      "           1       0.46      0.00      0.00     12653\n",
      "\n",
      "    accuracy                           0.78     58289\n",
      "   macro avg       0.62      0.50      0.44     58289\n",
      "weighted avg       0.71      0.78      0.69     58289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at classification_report\n",
    "y_pred =  logit_fitted.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a04bcf",
   "metadata": {},
   "source": [
    "Based on the precision, recall and f1-score, we see that logistic regression predicts pretty well on class 0 but poorly on class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854ce2bd",
   "metadata": {},
   "source": [
    "|  Logistic                |Class       |Precision |Recall   |F1\n",
    "|--------------------------|-------------|----------|---------|---\n",
    "| Train accuracy = 0.783  | Class  0   | 0.78     | 1.00    |  0.88\n",
    "| Test accuracy  = 0.783  | Class  1   | 0.46    | 0.00    |  0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a43cae",
   "metadata": {},
   "source": [
    "## 2. Neural Network  <a class=\"anchor\" id=\"nn\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12714bd8",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaff962",
   "metadata": {},
   "source": [
    "Let's start a baseline model with **4 hidden layers, 5 nodes each and 50 epoches**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26914300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 20:14:52.774212: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5465/5465 - 8s - loss: 0.5187 - binary_accuracy: 0.7816 - 8s/epoch - 1ms/step\n",
      "Epoch 2/50\n",
      "5465/5465 - 6s - loss: 0.5068 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 3/50\n",
      "5465/5465 - 6s - loss: 0.5048 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "5465/5465 - 6s - loss: 0.5039 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "5465/5465 - 6s - loss: 0.5034 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "5465/5465 - 6s - loss: 0.5029 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "5465/5465 - 6s - loss: 0.5028 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 8/50\n",
      "5465/5465 - 6s - loss: 0.5023 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 9/50\n",
      "5465/5465 - 6s - loss: 0.5023 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 10/50\n",
      "5465/5465 - 7s - loss: 0.5021 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 11/50\n",
      "5465/5465 - 6s - loss: 0.5018 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 12/50\n",
      "5465/5465 - 6s - loss: 0.5020 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 13/50\n",
      "5465/5465 - 6s - loss: 0.5015 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 14/50\n",
      "5465/5465 - 7s - loss: 0.5019 - binary_accuracy: 0.7830 - 7s/epoch - 1ms/step\n",
      "Epoch 15/50\n",
      "5465/5465 - 7s - loss: 0.5015 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 16/50\n",
      "5465/5465 - 7s - loss: 0.5014 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 17/50\n",
      "5465/5465 - 7s - loss: 0.5010 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 18/50\n",
      "5465/5465 - 7s - loss: 0.5014 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 19/50\n",
      "5465/5465 - 6s - loss: 0.5011 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 20/50\n",
      "5465/5465 - 8s - loss: 0.5012 - binary_accuracy: 0.7830 - 8s/epoch - 1ms/step\n",
      "Epoch 21/50\n",
      "5465/5465 - 8s - loss: 0.5009 - binary_accuracy: 0.7830 - 8s/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "5465/5465 - 7s - loss: 0.5009 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 23/50\n",
      "5465/5465 - 7s - loss: 0.5009 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 24/50\n",
      "5465/5465 - 6s - loss: 0.5011 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 25/50\n",
      "5465/5465 - 7s - loss: 0.5009 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 26/50\n",
      "5465/5465 - 6s - loss: 0.5006 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 27/50\n",
      "5465/5465 - 6s - loss: 0.5008 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 28/50\n",
      "5465/5465 - 8s - loss: 0.5008 - binary_accuracy: 0.7829 - 8s/epoch - 1ms/step\n",
      "Epoch 29/50\n",
      "5465/5465 - 7s - loss: 0.5010 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 30/50\n",
      "5465/5465 - 7s - loss: 0.5007 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 31/50\n",
      "5465/5465 - 7s - loss: 0.5007 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 32/50\n",
      "5465/5465 - 7s - loss: 0.5007 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 33/50\n",
      "5465/5465 - 7s - loss: 0.5006 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 34/50\n",
      "5465/5465 - 7s - loss: 0.5006 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 35/50\n",
      "5465/5465 - 7s - loss: 0.5006 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 36/50\n",
      "5465/5465 - 6s - loss: 0.5007 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 37/50\n",
      "5465/5465 - 6s - loss: 0.5006 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "5465/5465 - 6s - loss: 0.5006 - binary_accuracy: 0.7830 - 6s/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "5465/5465 - 6s - loss: 0.5005 - binary_accuracy: 0.7830 - 6s/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "5465/5465 - 7s - loss: 0.5007 - binary_accuracy: 0.7830 - 7s/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "5465/5465 - 7s - loss: 0.5005 - binary_accuracy: 0.7829 - 7s/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "5465/5465 - 6s - loss: 0.5008 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "5465/5465 - 6s - loss: 0.5005 - binary_accuracy: 0.7830 - 6s/epoch - 1ms/step\n",
      "Epoch 44/50\n",
      "[CV 3/5] END classifier__C=0.0001;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 2/5] END classifier__C=0.01;, score=(train=0.783, test=0.783) total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END classifier__C=0.001;, score=(train=0.783, test=0.783) total time=   2.9s\n",
      "[CV 5/5] END classifier__C=0.01;, score=(train=0.783, test=0.783) total time=   4.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END classifier__C=0.001;, score=(train=0.783, test=0.783) total time=   2.8s\n",
      "[CV 4/5] END classifier__C=0.01;, score=(train=0.783, test=0.783) total time=   4.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END classifier__C=0.001;, score=(train=0.783, test=0.782) total time=   3.1s\n",
      "[CV 1/5] END classifier__C=0.1;, score=(train=0.783, test=0.783) total time=   5.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5465/5465 - 6s - loss: 0.5006 - binary_accuracy: 0.7830 - 6s/epoch - 1ms/step\n",
      "Epoch 45/50\n",
      "[CV 5/5] END classifier__C=0.0001;, score=(train=0.783, test=0.783) total time=   1.7s\n",
      "[CV 4/5] END classifier__C=0.001;, score=(train=0.783, test=0.783) total time=   2.9s\n",
      "[CV 3/5] END classifier__C=0.1;, score=(train=0.783, test=0.782) total time=   4.5s\n",
      "[CV 2/5] END classifier__C=0.0001;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__C=0.001;, score=(train=0.783, test=0.783) total time=   2.8s\n",
      "[CV 2/5] END classifier__C=0.1;, score=(train=0.783, test=0.783) total time=   4.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END classifier__C=0.0001;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 1/5] END classifier__C=0.01;, score=(train=0.783, test=0.783) total time=   4.2s\n",
      "[CV 4/5] END classifier__C=0.1;, score=(train=0.783, test=0.782) total time=   3.7s\n",
      "[CV 4/5] END classifier__C=0.0001;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 3/5] END classifier__C=0.01;, score=(train=0.783, test=0.782) total time=   4.6s\n",
      "[CV 5/5] END classifier__C=0.1;, score=(train=0.783, test=0.783) total time=   3.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5465/5465 - 6s - loss: 0.5008 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 46/50\n",
      "5465/5465 - 6s - loss: 0.5005 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 47/50\n",
      "5465/5465 - 6s - loss: 0.5004 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 48/50\n",
      "5465/5465 - 6s - loss: 0.5002 - binary_accuracy: 0.7829 - 6s/epoch - 1ms/step\n",
      "Epoch 49/50\n",
      "5465/5465 - 6s - loss: 0.5003 - binary_accuracy: 0.7828 - 6s/epoch - 1ms/step\n",
      "Epoch 50/50\n",
      "5465/5465 - 6s - loss: 0.5004 - binary_accuracy: 0.7830 - 6s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# random seeds for reproducibility\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# Create a new sequential model\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Declare the hidden layers\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization()) \n",
    "\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization()) \n",
    "\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.BatchNormalization()) \n",
    "\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "\n",
    "# Declare the output layer\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics= keras.metrics.BinaryAccuracy())\n",
    "\n",
    "# define the pipeline\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "X_train_transformed = pipe.fit_transform(X_train)\n",
    "\n",
    "# transform test set\n",
    "X_test_transformed = pipe.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_transformed, y_train, epochs=50, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6c0891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1822/1822 [==============================] - 2s 726us/step - loss: 0.4999 - binary_accuracy: 0.7828\n",
      "Train Accuracy: 0.783\n",
      "Test Accuracy: 0.783\n",
      "Accuracy difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Score\n",
    "train_accuracy = history.history[\"binary_accuracy\"][-1]\n",
    "test_accuracy = model.evaluate(X_test_transformed,y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {np.round(train_accuracy,3)}\")\n",
    "print(f\"Test Accuracy: {np.round(test_accuracy[1],3)}\")\n",
    "print(f\"Accuracy difference: {np.round(train_accuracy,3)-np.round(test_accuracy[1],3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba26e9",
   "metadata": {},
   "source": [
    "We see that this basic neural network gives the same result as logistic regression, **train accuracy = test accuracy = 0.783**, this is probably because our dataset is simple to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f732885b",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5afde380",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45562,    74],\n",
       "       [12588,    65]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "y_pred = model.predict(X_test_transformed).round().astype(int)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ddc09c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     45636\n",
      "           1       0.47      0.01      0.01     12653\n",
      "\n",
      "    accuracy                           0.78     58289\n",
      "   macro avg       0.63      0.50      0.44     58289\n",
      "weighted avg       0.71      0.78      0.69     58289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d084b6",
   "metadata": {},
   "source": [
    "|  Logistic                |Class       |Precision |Recall   |F1\n",
    "|--------------------------|-------------|----------|---------|---\n",
    "| Train accuracy = 0.783  | Class  0   | 0.78     | 1.00    |  0.88\n",
    "| Test accuracy  = 0.783  | Class  1   | 0.46    | 0.00    |  0.00\n",
    "\n",
    "|  Neuron Network          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.783 | Class  0    | 0.78    |  1.00   |   0.88\n",
    "| Test accuracy  = 0.783  | Class  1    | 0.47     | 0.01    |  0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ab8091",
   "metadata": {},
   "source": [
    "## 3. XGBoost  <a class=\"anchor\" id=\"xgb\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7c383bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(steps=[(\"preprocessor\", preprocessor), \n",
    "                       (\"classifier\", XGBClassifier(random_state=0))])\n",
    "parameters = {\n",
    "    'classifier__learning_rate': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'classifier__n_estimators': [50,70,80]}\n",
    "    \n",
    "xgb = GridSearchCV(pipe, parameters, n_jobs = -1, verbose = 3)\n",
    "xgb_fitted=xgb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2730f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters: {'classifier__learning_rate': 0.1, 'classifier__n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# best parameters \n",
    "print(f\"best parameters: {xgb_fitted.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b3c9047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.7836216509879049\n"
     ]
    }
   ],
   "source": [
    "# best score\n",
    "print(f\"best score: {xgb_fitted.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2130dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.785\n",
      "Test Accuracy: 0.784\n",
      "Accuracy difference: 0.0010000000000000009\n"
     ]
    }
   ],
   "source": [
    "# score\n",
    "print(f\"Train Accuracy: {xgb_fitted.score(X_train, y_train).round(3)}\")\n",
    "print(f\"Test Accuracy: {xgb_fitted.score(X_test, y_test).round(3)}\")\n",
    "print(f\"Accuracy difference: {xgb_fitted.score(X_train, y_train).round(3) - xgb_fitted.score(X_test, y_test).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fe19e",
   "metadata": {},
   "source": [
    "We see the same accuracy scores as Neural Network and Logistics Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bbdeab",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2422ea58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45593,    43],\n",
       "       [12567,    86]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "y_pred = xgb_fitted.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "867caa41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     45636\n",
      "           1       0.67      0.01      0.01     12653\n",
      "\n",
      "    accuracy                           0.78     58289\n",
      "   macro avg       0.73      0.50      0.45     58289\n",
      "weighted avg       0.76      0.78      0.69     58289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_test, y_pred));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889dd35",
   "metadata": {},
   "source": [
    "|  Logistic                |Class       |Precision |Recall   |F1\n",
    "|--------------------------|-------------|----------|---------|---\n",
    "| Train accuracy = 0.783  | Class  0   | 0.78     | 1.00    |  0.88\n",
    "| Test accuracy  = 0.783  | Class  1   | 0.46    | 0.00    |  0.00\n",
    "\n",
    "|  Neuron Network          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.783 | Class  0    | 0.78    |  1.00   |   0.88\n",
    "| Test accuracy  = 0.783  | Class  1    | 0.47     | 0.01    |  0.01\n",
    "\n",
    "|  XGBoost          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.785 | Class  0    |  0.78   |   1.00   |   0.88\n",
    "| Test accuracy  = 0.784  | Class  1    | 0.67    |  0.01    |  0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd27417",
   "metadata": {},
   "source": [
    "Given the same accuracies, XGBoost tends to perform better than Neural Network and Logistics Regression in terms of classifying class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96e2285",
   "metadata": {},
   "source": [
    "## 4. Random Forest  <a class=\"anchor\" id=\"rf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ae915",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7570d7dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.7s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   1.8s\n",
      "[CV 1/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 2/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 3/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 4/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__max_depth=10, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.4s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.4s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   1.9s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__learning_rate=0.0001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 1/5] END classifier__learning_rate=0.0001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 1/5] END classifier__learning_rate=0.001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 4/5] END classifier__learning_rate=0.001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 4/5] END classifier__learning_rate=0.01, classifier__n_estimators=70;, score=0.783 total time= 2.5min\n",
      "[CV 2/5] END classifier__learning_rate=0.1, classifier__n_estimators=50;, score=0.784 total time= 1.8min\n",
      "[CV 3/5] END classifier__learning_rate=0.1, classifier__n_estimators=70;, score=0.784 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 5/5] END classifier__learning_rate=0.0001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 3/5] END classifier__learning_rate=0.0001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 2/5] END classifier__learning_rate=0.001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 5/5] END classifier__learning_rate=0.001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 5/5] END classifier__learning_rate=0.01, classifier__n_estimators=70;, score=0.783 total time= 2.6min\n",
      "[CV 3/5] END classifier__learning_rate=0.1, classifier__n_estimators=50;, score=0.784 total time= 1.8min\n",
      "[CV 4/5] END classifier__learning_rate=0.1, classifier__n_estimators=70;, score=0.783 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 5/5] END classifier__max_depth=12, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__learning_rate=0.0001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 2/5] END classifier__learning_rate=0.0001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 5/5] END classifier__learning_rate=0.001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 3/5] END classifier__learning_rate=0.001, classifier__n_estimators=80;, score=0.783 total time= 2.4min\n",
      "[CV 1/5] END classifier__learning_rate=0.01, classifier__n_estimators=70;, score=0.783 total time= 2.4min\n",
      "[CV 4/5] END classifier__learning_rate=0.01, classifier__n_estimators=80;, score=0.783 total time= 2.9min\n",
      "[CV 5/5] END classifier__learning_rate=0.1, classifier__n_estimators=70;, score=0.783 total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 3/5] END classifier__learning_rate=0.0001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 5/5] END classifier__learning_rate=0.0001, classifier__n_estimators=80;, score=0.783 total time= 2.3min\n",
      "[CV 3/5] END classifier__learning_rate=0.001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 1/5] END classifier__learning_rate=0.01, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 2/5] END classifier__learning_rate=0.01, classifier__n_estimators=70;, score=0.783 total time= 2.4min\n",
      "[CV 5/5] END classifier__learning_rate=0.01, classifier__n_estimators=80;, score=0.783 total time= 2.8min\n",
      "[CV 1/5] END classifier__learning_rate=0.1, classifier__n_estimators=80;, score=0.784 total time= 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 4/5] END classifier__learning_rate=0.0001, classifier__n_estimators=50;, score=0.782 total time= 1.5min\n",
      "[CV 5/5] END classifier__learning_rate=0.0001, classifier__n_estimators=70;, score=0.783 total time= 2.0min\n",
      "[CV 2/5] END classifier__learning_rate=0.001, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 5/5] END classifier__learning_rate=0.001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 3/5] END classifier__learning_rate=0.01, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 1/5] END classifier__learning_rate=0.01, classifier__n_estimators=80;, score=0.783 total time= 2.9min\n",
      "[CV 4/5] END classifier__learning_rate=0.1, classifier__n_estimators=50;, score=0.783 total time= 1.8min\n",
      "[CV 2/5] END classifier__learning_rate=0.1, classifier__n_estimators=80;, score=0.784 total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 2/5] END classifier__learning_rate=0.0001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 1/5] END classifier__learning_rate=0.001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 3/5] END classifier__learning_rate=0.001, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 2/5] END classifier__learning_rate=0.001, classifier__n_estimators=80;, score=0.783 total time= 2.4min\n",
      "[CV 4/5] END classifier__learning_rate=0.01, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 2/5] END classifier__learning_rate=0.01, classifier__n_estimators=80;, score=0.783 total time= 3.0min\n",
      "[CV 5/5] END classifier__learning_rate=0.1, classifier__n_estimators=50;, score=0.783 total time= 1.8min\n",
      "[CV 3/5] END classifier__learning_rate=0.1, classifier__n_estimators=80;, score=0.784 total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=3, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__learning_rate=0.0001, classifier__n_estimators=50;, score=0.783 total time= 1.5min\n",
      "[CV 4/5] END classifier__learning_rate=0.0001, classifier__n_estimators=70;, score=0.782 total time= 2.1min\n",
      "[CV 4/5] END classifier__learning_rate=0.001, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 1/5] END classifier__learning_rate=0.001, classifier__n_estimators=80;, score=0.783 total time= 2.4min\n",
      "[CV 5/5] END classifier__learning_rate=0.01, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 3/5] END classifier__learning_rate=0.01, classifier__n_estimators=80;, score=0.783 total time= 3.0min\n",
      "[CV 1/5] END classifier__learning_rate=0.1, classifier__n_estimators=70;, score=0.784 total time= 2.4min\n",
      "[CV 4/5] END classifier__learning_rate=0.1, classifier__n_estimators=80;, score=0.783 total time= 1.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__learning_rate=0.0001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 4/5] END classifier__learning_rate=0.0001, classifier__n_estimators=80;, score=0.782 total time= 2.3min\n",
      "[CV 4/5] END classifier__learning_rate=0.001, classifier__n_estimators=70;, score=0.783 total time= 2.1min\n",
      "[CV 2/5] END classifier__learning_rate=0.01, classifier__n_estimators=50;, score=0.783 total time= 1.4min\n",
      "[CV 3/5] END classifier__learning_rate=0.01, classifier__n_estimators=70;, score=0.783 total time= 2.5min\n",
      "[CV 1/5] END classifier__learning_rate=0.1, classifier__n_estimators=50;, score=0.784 total time= 1.8min\n",
      "[CV 2/5] END classifier__learning_rate=0.1, classifier__n_estimators=70;, score=0.784 total time= 2.3min\n",
      "[CV 5/5] END classifier__learning_rate=0.1, classifier__n_estimators=80;, score=0.783 total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/thao/opt/anaconda3/envs/ensemble/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=5, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=35;, score=(train=0.783, test=0.783) total time=   2.0s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=37;, score=(train=0.783, test=0.783) total time=   2.1s\n",
      "[CV 1/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 2/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 3/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.3s\n",
      "[CV 4/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n",
      "[CV 5/5] END classifier__max_depth=14, classifier__min_samples_leaf=7, classifier__n_estimators=39;, score=(train=0.783, test=0.783) total time=   2.2s\n"
     ]
    }
   ],
   "source": [
    "rf_preprocessor = ColumnTransformer(transformers=[(\"ohe\", ohe, categorical_features)])\n",
    "\n",
    "# instantiate\n",
    "pipe = Pipeline(steps=[(\"preprocessor\", rf_preprocessor), \n",
    "                       (\"classifier\", RandomForestClassifier(random_state=10))])\n",
    "\n",
    "param_grid = {'classifier__n_estimators':[35,37,39],\n",
    "              'classifier__max_depth':[10,12,14],\n",
    "              'classifier__min_samples_leaf':[3,5,7]}\n",
    "\n",
    "rf = GridSearchCV(pipe, param_grid, verbose=3, return_train_score=True)\n",
    "\n",
    "# fit\n",
    "rf_fitted=rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a274d1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__max_depth': 10,\n",
       " 'classifier__min_samples_leaf': 3,\n",
       " 'classifier__n_estimators': 35}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best model\n",
    "rf_fitted.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8f1cea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829296886169329"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best validation score\n",
    "rf_fitted.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2617235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.783\n",
      "Test Accuracy: 0.783\n",
      "Accuracy difference: 0.0\n"
     ]
    }
   ],
   "source": [
    "# score\n",
    "print(f\"Train Accuracy: {rf_fitted.score(X_train, y_train).round(3)}\")\n",
    "print(f\"Test Accuracy: {rf_fitted.score(X_test, y_test).round(3)}\")\n",
    "print(f\"Accuracy difference: {(rf_fitted.score(X_train, y_train) - rf_fitted.score(X_test, y_test)).round(3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae68f0ce",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d626af1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45636,     0],\n",
       "       [12653,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "y_pred = rf_fitted.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c5d255e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88     45636\n",
      "           1       0.00      0.00      0.00     12653\n",
      "\n",
      "    accuracy                           0.78     58289\n",
      "   macro avg       0.39      0.50      0.44     58289\n",
      "weighted avg       0.61      0.78      0.69     58289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdef53",
   "metadata": {},
   "source": [
    "|  Logistic                |Class       |Precision |Recall   |F1\n",
    "|--------------------------|-------------|----------|---------|---\n",
    "| Train accuracy = 0.783  | Class  0   | 0.78     | 1.00    |  0.88\n",
    "| Test accuracy  = 0.783  | Class  1   | 0.46    | 0.00    |  0.00\n",
    "\n",
    "|  Neuron Network          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.783 | Class  0    | 0.78    |  1.00   |   0.88\n",
    "| Test accuracy  = 0.783  | Class  1    | 0.47     | 0.01    |  0.01\n",
    "\n",
    "|  XGBoost          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.785 | Class  0    |  0.78   |   1.00   |   0.88\n",
    "| Test accuracy  = 0.784  | Class  1    | 0.67    |  0.01    |  0.01\n",
    "\n",
    "|  Random Forest          |Class  |Precision     |Recall      |F1\n",
    "|--------------------------|----------------|--------------|--------------|---\n",
    "| Train accuracy = 0.783 | Class  0    | 0.78    |  1.00   |   0.88\n",
    "| Test accuracy  = 0.783  | Class  1    | 0.00     | 0.00    |  0.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7091f8",
   "metadata": {},
   "source": [
    "We see that throughout 4 models, the accuracies are constant around **78.3%**, this means that this is the best accuracy that could be learned from this dataset. At threshold 0.5, this level of accuracy is not ideal at all, so to improve the accuracy or to more precisely classify the target, the dataset would require additional important features that are highly meaningful to the target. This necessitates domain expertise and is a room for improvement.\n",
    "\n",
    "Misclassifying class 1 would cause significantly financial losses, therefore recall of class 1 should be prioritized. Let's adjust threshold to see which one would give the ideal learning result for class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c246eb",
   "metadata": {},
   "source": [
    "# Threshold Adjustment <a class=\"anchor\" id=\"#threshold\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "574229a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds = np.arange(0.1, 0.51, 0.01)\n",
    "\n",
    "##################### LOGISTIC\n",
    "lg_precision_1 = []\n",
    "lg_recall_1 = []\n",
    "lg_precision_0 = []\n",
    "lg_recall_0 = []\n",
    "\n",
    "# Make probabilistic predictions (scores)\n",
    "logit_y_proba_train = logit_fitted.predict_proba(X_train)[:,1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "\n",
    "    # Apply threshold\n",
    "    y_threshold = np.where(logit_y_proba_train >= threshold, 1, 0)\n",
    "    logit_report=classification_report(y_train, y_threshold,output_dict=True)\n",
    "\n",
    "    # Class 1\n",
    "    lg_precision_1.append(logit_report['1']['precision'])\n",
    "    lg_recall_1.append(logit_report['1']['recall'])\n",
    "    \n",
    "    # Class 0\n",
    "    lg_precision_0.append(logit_report['0']['precision'])\n",
    "    lg_recall_0.append(logit_report['0']['recall'])\n",
    "    \n",
    "##################### NEURAL NETWORK\n",
    "nn_precision_1=[]\n",
    "nn_recall_1=[]\n",
    "nn_precision_0=[]\n",
    "nn_recall_0=[]\n",
    "\n",
    "nn_y_proba_train= model.predict(X_train_transformed)\n",
    "\n",
    "for threshold in thresholds:\n",
    "\n",
    "    # Apply threshold\n",
    "    y_threshold = np.where(nn_y_proba_train >= threshold, 1, 0)\n",
    "    nn_report=classification_report(y_train, y_threshold,output_dict=True)\n",
    "\n",
    "    # Class 1   \n",
    "    nn_precision_1.append(nn_report['1']['precision'])\n",
    "    nn_recall_1.append(nn_report['1']['recall'])\n",
    "    \n",
    "    # Class 0\n",
    "    nn_precision_0.append(nn_report['0']['precision'])\n",
    "    nn_recall_0.append(nn_report['0']['recall'])\n",
    "\n",
    "##################### XGBoost\n",
    "xg_precision_1 = []\n",
    "xg_recall_1 = []\n",
    "xg_precision_0 = []\n",
    "xg_recall_0 = []\n",
    "\n",
    "xg_y_proba_train=xgb_fitted.predict_proba(X_train)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "\n",
    "    # Apply threshold\n",
    "    y_threshold = np.where(xg_y_proba_train >= threshold, 1, 0)\n",
    "    xg_report=classification_report(y_train, y_threshold,output_dict=True)\n",
    "\n",
    "    # class 1\n",
    "    xg_precision_1.append(xg_report['1']['precision'])\n",
    "    xg_recall_1.append(xg_report['1']['recall'])\n",
    "    \n",
    "    # class 0\n",
    "    xg_precision_0.append(xg_report['0']['precision'])\n",
    "    xg_recall_0.append(xg_report['0']['recall'])\n",
    "    \n",
    "##################### RANDOM FOREST    \n",
    "rf_precision_1 = []\n",
    "rf_recall_1 = []\n",
    "rf_precision_0 = []\n",
    "rf_recall_0 = []\n",
    "\n",
    "rf_y_proba_train=rf_fitted.predict_proba(X_train)[:, 1]\n",
    "\n",
    "for threshold in thresholds:\n",
    "\n",
    "    # Apply threshold\n",
    "    y_threshold = np.where(rf_y_proba_train >= threshold, 1, 0)\n",
    "    rf_report=classification_report(y_train, y_threshold,output_dict=True)\n",
    "    \n",
    "    # class 1 \n",
    "    rf_precision_1.append(rf_report['1']['precision'])\n",
    "    rf_recall_1.append(rf_report['1']['recall'])\n",
    "    \n",
    "    # class 0 \n",
    "    rf_precision_0.append(rf_report['0']['precision'])\n",
    "    rf_recall_0.append(rf_report['0']['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17ad467b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LG_precision_1</th>\n",
       "      <th>LG_recall_1</th>\n",
       "      <th>NN_precision_1</th>\n",
       "      <th>NN_recall_1</th>\n",
       "      <th>XG_precision_1</th>\n",
       "      <th>XG_recall_1</th>\n",
       "      <th>RF_precision_1</th>\n",
       "      <th>RF_recall_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.219469</td>\n",
       "      <td>0.993914</td>\n",
       "      <td>0.231542</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>0.228712</td>\n",
       "      <td>0.988224</td>\n",
       "      <td>0.217070</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.11</th>\n",
       "      <td>0.221004</td>\n",
       "      <td>0.989884</td>\n",
       "      <td>0.236926</td>\n",
       "      <td>0.943622</td>\n",
       "      <td>0.233743</td>\n",
       "      <td>0.979451</td>\n",
       "      <td>0.217070</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.222938</td>\n",
       "      <td>0.983087</td>\n",
       "      <td>0.242770</td>\n",
       "      <td>0.921993</td>\n",
       "      <td>0.239305</td>\n",
       "      <td>0.967043</td>\n",
       "      <td>0.217070</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.13</th>\n",
       "      <td>0.225801</td>\n",
       "      <td>0.974366</td>\n",
       "      <td>0.248520</td>\n",
       "      <td>0.899231</td>\n",
       "      <td>0.245628</td>\n",
       "      <td>0.952026</td>\n",
       "      <td>0.219204</td>\n",
       "      <td>0.989936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.229056</td>\n",
       "      <td>0.962195</td>\n",
       "      <td>0.253979</td>\n",
       "      <td>0.878287</td>\n",
       "      <td>0.252537</td>\n",
       "      <td>0.934322</td>\n",
       "      <td>0.219204</td>\n",
       "      <td>0.989936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.233156</td>\n",
       "      <td>0.945571</td>\n",
       "      <td>0.259167</td>\n",
       "      <td>0.853522</td>\n",
       "      <td>0.259218</td>\n",
       "      <td>0.913062</td>\n",
       "      <td>0.221248</td>\n",
       "      <td>0.974498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.238190</td>\n",
       "      <td>0.924100</td>\n",
       "      <td>0.264672</td>\n",
       "      <td>0.827862</td>\n",
       "      <td>0.266877</td>\n",
       "      <td>0.889957</td>\n",
       "      <td>0.222771</td>\n",
       "      <td>0.961695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.17</th>\n",
       "      <td>0.244196</td>\n",
       "      <td>0.896754</td>\n",
       "      <td>0.269847</td>\n",
       "      <td>0.799673</td>\n",
       "      <td>0.274376</td>\n",
       "      <td>0.864113</td>\n",
       "      <td>0.226633</td>\n",
       "      <td>0.920755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <td>0.250773</td>\n",
       "      <td>0.860741</td>\n",
       "      <td>0.274964</td>\n",
       "      <td>0.769772</td>\n",
       "      <td>0.282271</td>\n",
       "      <td>0.835160</td>\n",
       "      <td>0.227523</td>\n",
       "      <td>0.911112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.19</th>\n",
       "      <td>0.258320</td>\n",
       "      <td>0.817140</td>\n",
       "      <td>0.280208</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>0.290284</td>\n",
       "      <td>0.805390</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.836398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>0.266450</td>\n",
       "      <td>0.763950</td>\n",
       "      <td>0.285405</td>\n",
       "      <td>0.709363</td>\n",
       "      <td>0.298463</td>\n",
       "      <td>0.770589</td>\n",
       "      <td>0.237252</td>\n",
       "      <td>0.791849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.275346</td>\n",
       "      <td>0.701828</td>\n",
       "      <td>0.291325</td>\n",
       "      <td>0.677090</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.733495</td>\n",
       "      <td>0.241104</td>\n",
       "      <td>0.734391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>0.284039</td>\n",
       "      <td>0.630381</td>\n",
       "      <td>0.297720</td>\n",
       "      <td>0.642210</td>\n",
       "      <td>0.316778</td>\n",
       "      <td>0.693451</td>\n",
       "      <td>0.242587</td>\n",
       "      <td>0.689051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.23</th>\n",
       "      <td>0.293594</td>\n",
       "      <td>0.553348</td>\n",
       "      <td>0.303831</td>\n",
       "      <td>0.601691</td>\n",
       "      <td>0.326098</td>\n",
       "      <td>0.647531</td>\n",
       "      <td>0.252290</td>\n",
       "      <td>0.463591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.24</th>\n",
       "      <td>0.303406</td>\n",
       "      <td>0.472654</td>\n",
       "      <td>0.310799</td>\n",
       "      <td>0.558960</td>\n",
       "      <td>0.337362</td>\n",
       "      <td>0.600769</td>\n",
       "      <td>0.288870</td>\n",
       "      <td>0.119184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.313102</td>\n",
       "      <td>0.392486</td>\n",
       "      <td>0.317128</td>\n",
       "      <td>0.511434</td>\n",
       "      <td>0.349471</td>\n",
       "      <td>0.553981</td>\n",
       "      <td>0.289155</td>\n",
       "      <td>0.118289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.26</th>\n",
       "      <td>0.322700</td>\n",
       "      <td>0.315796</td>\n",
       "      <td>0.324635</td>\n",
       "      <td>0.465383</td>\n",
       "      <td>0.359859</td>\n",
       "      <td>0.503109</td>\n",
       "      <td>0.298372</td>\n",
       "      <td>0.084014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.27</th>\n",
       "      <td>0.332838</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.331820</td>\n",
       "      <td>0.414089</td>\n",
       "      <td>0.372680</td>\n",
       "      <td>0.456057</td>\n",
       "      <td>0.298372</td>\n",
       "      <td>0.084014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.28</th>\n",
       "      <td>0.345436</td>\n",
       "      <td>0.191501</td>\n",
       "      <td>0.340258</td>\n",
       "      <td>0.371964</td>\n",
       "      <td>0.385741</td>\n",
       "      <td>0.408241</td>\n",
       "      <td>0.304813</td>\n",
       "      <td>0.052558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.29</th>\n",
       "      <td>0.358144</td>\n",
       "      <td>0.146794</td>\n",
       "      <td>0.347393</td>\n",
       "      <td>0.331551</td>\n",
       "      <td>0.399441</td>\n",
       "      <td>0.361452</td>\n",
       "      <td>0.307844</td>\n",
       "      <td>0.032878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.369729</td>\n",
       "      <td>0.110886</td>\n",
       "      <td>0.355454</td>\n",
       "      <td>0.296196</td>\n",
       "      <td>0.415328</td>\n",
       "      <td>0.317377</td>\n",
       "      <td>0.307844</td>\n",
       "      <td>0.032878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.31</th>\n",
       "      <td>0.385309</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.361885</td>\n",
       "      <td>0.262237</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>0.276332</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.403295</td>\n",
       "      <td>0.064492</td>\n",
       "      <td>0.370930</td>\n",
       "      <td>0.232283</td>\n",
       "      <td>0.447124</td>\n",
       "      <td>0.238369</td>\n",
       "      <td>0.357798</td>\n",
       "      <td>0.001027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.33</th>\n",
       "      <td>0.414752</td>\n",
       "      <td>0.047553</td>\n",
       "      <td>0.379415</td>\n",
       "      <td>0.204041</td>\n",
       "      <td>0.464675</td>\n",
       "      <td>0.205332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.34</th>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.035302</td>\n",
       "      <td>0.387230</td>\n",
       "      <td>0.177670</td>\n",
       "      <td>0.481699</td>\n",
       "      <td>0.174746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.431483</td>\n",
       "      <td>0.026213</td>\n",
       "      <td>0.396662</td>\n",
       "      <td>0.154671</td>\n",
       "      <td>0.495936</td>\n",
       "      <td>0.149481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.36</th>\n",
       "      <td>0.438484</td>\n",
       "      <td>0.019811</td>\n",
       "      <td>0.405987</td>\n",
       "      <td>0.133621</td>\n",
       "      <td>0.507136</td>\n",
       "      <td>0.126377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.37</th>\n",
       "      <td>0.447347</td>\n",
       "      <td>0.014437</td>\n",
       "      <td>0.411153</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.529729</td>\n",
       "      <td>0.108673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.38</th>\n",
       "      <td>0.432343</td>\n",
       "      <td>0.010354</td>\n",
       "      <td>0.420056</td>\n",
       "      <td>0.098214</td>\n",
       "      <td>0.544383</td>\n",
       "      <td>0.091285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.39</th>\n",
       "      <td>0.402985</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.429974</td>\n",
       "      <td>0.084198</td>\n",
       "      <td>0.556827</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>0.401835</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>0.072264</td>\n",
       "      <td>0.579919</td>\n",
       "      <td>0.064519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.41</th>\n",
       "      <td>0.394273</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.448069</td>\n",
       "      <td>0.061147</td>\n",
       "      <td>0.598483</td>\n",
       "      <td>0.054033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.392308</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.453640</td>\n",
       "      <td>0.050398</td>\n",
       "      <td>0.613043</td>\n",
       "      <td>0.044576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.43</th>\n",
       "      <td>0.393189</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.455448</td>\n",
       "      <td>0.041072</td>\n",
       "      <td>0.633003</td>\n",
       "      <td>0.036988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.44</th>\n",
       "      <td>0.376307</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.466083</td>\n",
       "      <td>0.033669</td>\n",
       "      <td>0.654704</td>\n",
       "      <td>0.031719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.391667</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.477897</td>\n",
       "      <td>0.027056</td>\n",
       "      <td>0.677160</td>\n",
       "      <td>0.026635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.46</th>\n",
       "      <td>0.376147</td>\n",
       "      <td>0.002160</td>\n",
       "      <td>0.483891</td>\n",
       "      <td>0.020180</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.022393</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.47</th>\n",
       "      <td>0.357513</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.484202</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.717975</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48</th>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.501190</td>\n",
       "      <td>0.011091</td>\n",
       "      <td>0.748062</td>\n",
       "      <td>0.015254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.49</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.001581</td>\n",
       "      <td>0.513378</td>\n",
       "      <td>0.008088</td>\n",
       "      <td>0.777244</td>\n",
       "      <td>0.012777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.375887</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>0.520581</td>\n",
       "      <td>0.005664</td>\n",
       "      <td>0.793522</td>\n",
       "      <td>0.010327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LG_precision_1  LG_recall_1  NN_precision_1  NN_recall_1  \\\n",
       "0.10        0.219469     0.993914        0.231542     0.962406   \n",
       "0.11        0.221004     0.989884        0.236926     0.943622   \n",
       "0.12        0.222938     0.983087        0.242770     0.921993   \n",
       "0.13        0.225801     0.974366        0.248520     0.899231   \n",
       "0.14        0.229056     0.962195        0.253979     0.878287   \n",
       "0.15        0.233156     0.945571        0.259167     0.853522   \n",
       "0.16        0.238190     0.924100        0.264672     0.827862   \n",
       "0.17        0.244196     0.896754        0.269847     0.799673   \n",
       "0.18        0.250773     0.860741        0.274964     0.769772   \n",
       "0.19        0.258320     0.817140        0.280208     0.740634   \n",
       "0.20        0.266450     0.763950        0.285405     0.709363   \n",
       "0.21        0.275346     0.701828        0.291325     0.677090   \n",
       "0.22        0.284039     0.630381        0.297720     0.642210   \n",
       "0.23        0.293594     0.553348        0.303831     0.601691   \n",
       "0.24        0.303406     0.472654        0.310799     0.558960   \n",
       "0.25        0.313102     0.392486        0.317128     0.511434   \n",
       "0.26        0.322700     0.315796        0.324635     0.465383   \n",
       "0.27        0.332838     0.247800        0.331820     0.414089   \n",
       "0.28        0.345436     0.191501        0.340258     0.371964   \n",
       "0.29        0.358144     0.146794        0.347393     0.331551   \n",
       "0.30        0.369729     0.110886        0.355454     0.296196   \n",
       "0.31        0.385309     0.084435        0.361885     0.262237   \n",
       "0.32        0.403295     0.064492        0.370930     0.232283   \n",
       "0.33        0.414752     0.047553        0.379415     0.204041   \n",
       "0.34        0.425397     0.035302        0.387230     0.177670   \n",
       "0.35        0.431483     0.026213        0.396662     0.154671   \n",
       "0.36        0.438484     0.019811        0.405987     0.133621   \n",
       "0.37        0.447347     0.014437        0.411153     0.114600   \n",
       "0.38        0.432343     0.010354        0.420056     0.098214   \n",
       "0.39        0.402985     0.007113        0.429974     0.084198   \n",
       "0.40        0.401835     0.005770        0.439583     0.072264   \n",
       "0.41        0.394273     0.004716        0.448069     0.061147   \n",
       "0.42        0.392308     0.004031        0.453640     0.050398   \n",
       "0.43        0.393189     0.003346        0.455448     0.041072   \n",
       "0.44        0.376307     0.002845        0.466083     0.033669   \n",
       "0.45        0.391667     0.002476        0.477897     0.027056   \n",
       "0.46        0.376147     0.002160        0.483891     0.020180   \n",
       "0.47        0.357513     0.001818        0.484202     0.014938   \n",
       "0.48        0.356322     0.001633        0.501190     0.011091   \n",
       "0.49        0.384615     0.001581        0.513378     0.008088   \n",
       "0.50        0.375887     0.001396        0.520581     0.005664   \n",
       "\n",
       "      XG_precision_1  XG_recall_1  RF_precision_1  RF_recall_1  \n",
       "0.10        0.228712     0.988224        0.217070     1.000000  \n",
       "0.11        0.233743     0.979451        0.217070     1.000000  \n",
       "0.12        0.239305     0.967043        0.217070     1.000000  \n",
       "0.13        0.245628     0.952026        0.219204     0.989936  \n",
       "0.14        0.252537     0.934322        0.219204     0.989936  \n",
       "0.15        0.259218     0.913062        0.221248     0.974498  \n",
       "0.16        0.266877     0.889957        0.222771     0.961695  \n",
       "0.17        0.274376     0.864113        0.226633     0.920755  \n",
       "0.18        0.282271     0.835160        0.227523     0.911112  \n",
       "0.19        0.290284     0.805390        0.234415     0.836398  \n",
       "0.20        0.298463     0.770589        0.237252     0.791849  \n",
       "0.21        0.307524     0.733495        0.241104     0.734391  \n",
       "0.22        0.316778     0.693451        0.242587     0.689051  \n",
       "0.23        0.326098     0.647531        0.252290     0.463591  \n",
       "0.24        0.337362     0.600769        0.288870     0.119184  \n",
       "0.25        0.349471     0.553981        0.289155     0.118289  \n",
       "0.26        0.359859     0.503109        0.298372     0.084014  \n",
       "0.27        0.372680     0.456057        0.298372     0.084014  \n",
       "0.28        0.385741     0.408241        0.304813     0.052558  \n",
       "0.29        0.399441     0.361452        0.307844     0.032878  \n",
       "0.30        0.415328     0.317377        0.307844     0.032878  \n",
       "0.31        0.430300     0.276332        0.357798     0.001027  \n",
       "0.32        0.447124     0.238369        0.357798     0.001027  \n",
       "0.33        0.464675     0.205332        0.000000     0.000000  \n",
       "0.34        0.481699     0.174746        0.000000     0.000000  \n",
       "0.35        0.495936     0.149481        0.000000     0.000000  \n",
       "0.36        0.507136     0.126377        0.000000     0.000000  \n",
       "0.37        0.529729     0.108673        0.000000     0.000000  \n",
       "0.38        0.544383     0.091285        0.000000     0.000000  \n",
       "0.39        0.556827     0.075636        0.000000     0.000000  \n",
       "0.40        0.579919     0.064519        0.000000     0.000000  \n",
       "0.41        0.598483     0.054033        0.000000     0.000000  \n",
       "0.42        0.613043     0.044576        0.000000     0.000000  \n",
       "0.43        0.633003     0.036988        0.000000     0.000000  \n",
       "0.44        0.654704     0.031719        0.000000     0.000000  \n",
       "0.45        0.677160     0.026635        0.000000     0.000000  \n",
       "0.46        0.693878     0.022393        0.000000     0.000000  \n",
       "0.47        0.717975     0.018310        0.000000     0.000000  \n",
       "0.48        0.748062     0.015254        0.000000     0.000000  \n",
       "0.49        0.777244     0.012777        0.000000     0.000000  \n",
       "0.50        0.793522     0.010327        0.000000     0.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_1=pd.DataFrame({'LG_precision_1':lg_precision_1, 'LG_recall_1': lg_recall_1,\\\n",
    "                 'NN_precision_1':nn_precision_1,'NN_recall_1':nn_recall_1,\\\n",
    "                 'XG_precision_1':xg_precision_1,'XG_recall_1':xg_recall_1,\\\n",
    "                 'RF_precision_1':rf_precision_1,'RF_recall_1':rf_recall_1},index=thresholds)\n",
    "class_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27dc650c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LG_precision_0</th>\n",
       "      <th>LG_recall_0</th>\n",
       "      <th>NN_precision_0</th>\n",
       "      <th>NN_recall_0</th>\n",
       "      <th>XG_precision_0</th>\n",
       "      <th>XG_recall_0</th>\n",
       "      <th>RF_precision_0</th>\n",
       "      <th>RF_recall_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>0.922065</td>\n",
       "      <td>0.019962</td>\n",
       "      <td>0.916511</td>\n",
       "      <td>0.114421</td>\n",
       "      <td>0.958821</td>\n",
       "      <td>0.076022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.11</th>\n",
       "      <td>0.920825</td>\n",
       "      <td>0.032621</td>\n",
       "      <td>0.909655</td>\n",
       "      <td>0.157384</td>\n",
       "      <td>0.950664</td>\n",
       "      <td>0.109783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.12</th>\n",
       "      <td>0.914194</td>\n",
       "      <td>0.049961</td>\n",
       "      <td>0.903576</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>0.941746</td>\n",
       "      <td>0.147721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.13</th>\n",
       "      <td>0.912105</td>\n",
       "      <td>0.073751</td>\n",
       "      <td>0.898054</td>\n",
       "      <td>0.246116</td>\n",
       "      <td>0.934364</td>\n",
       "      <td>0.189348</td>\n",
       "      <td>0.889115</td>\n",
       "      <td>0.022373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.14</th>\n",
       "      <td>0.906909</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.894042</td>\n",
       "      <td>0.284733</td>\n",
       "      <td>0.927592</td>\n",
       "      <td>0.233275</td>\n",
       "      <td>0.889115</td>\n",
       "      <td>0.022373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.15</th>\n",
       "      <td>0.901266</td>\n",
       "      <td>0.137750</td>\n",
       "      <td>0.888481</td>\n",
       "      <td>0.323555</td>\n",
       "      <td>0.919831</td>\n",
       "      <td>0.276560</td>\n",
       "      <td>0.873909</td>\n",
       "      <td>0.049004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.16</th>\n",
       "      <td>0.895616</td>\n",
       "      <td>0.180553</td>\n",
       "      <td>0.883606</td>\n",
       "      <td>0.362312</td>\n",
       "      <td>0.913495</td>\n",
       "      <td>0.322182</td>\n",
       "      <td>0.867842</td>\n",
       "      <td>0.069741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.17</th>\n",
       "      <td>0.889522</td>\n",
       "      <td>0.230478</td>\n",
       "      <td>0.878100</td>\n",
       "      <td>0.400089</td>\n",
       "      <td>0.906762</td>\n",
       "      <td>0.366402</td>\n",
       "      <td>0.854341</td>\n",
       "      <td>0.128869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.18</th>\n",
       "      <td>0.881427</td>\n",
       "      <td>0.287012</td>\n",
       "      <td>0.872609</td>\n",
       "      <td>0.437238</td>\n",
       "      <td>0.899981</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.852425</td>\n",
       "      <td>0.142352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.19</th>\n",
       "      <td>0.873323</td>\n",
       "      <td>0.349522</td>\n",
       "      <td>0.867916</td>\n",
       "      <td>0.472518</td>\n",
       "      <td>0.893790</td>\n",
       "      <td>0.454060</td>\n",
       "      <td>0.842506</td>\n",
       "      <td>0.242646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>0.864312</td>\n",
       "      <td>0.416882</td>\n",
       "      <td>0.862994</td>\n",
       "      <td>0.507571</td>\n",
       "      <td>0.886708</td>\n",
       "      <td>0.497820</td>\n",
       "      <td>0.836001</td>\n",
       "      <td>0.294185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.21</th>\n",
       "      <td>0.855109</td>\n",
       "      <td>0.487893</td>\n",
       "      <td>0.858536</td>\n",
       "      <td>0.543340</td>\n",
       "      <td>0.880041</td>\n",
       "      <td>0.542069</td>\n",
       "      <td>0.829831</td>\n",
       "      <td>0.359112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.22</th>\n",
       "      <td>0.845183</td>\n",
       "      <td>0.559453</td>\n",
       "      <td>0.853946</td>\n",
       "      <td>0.579992</td>\n",
       "      <td>0.873208</td>\n",
       "      <td>0.585332</td>\n",
       "      <td>0.823962</td>\n",
       "      <td>0.403522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.23</th>\n",
       "      <td>0.835914</td>\n",
       "      <td>0.630866</td>\n",
       "      <td>0.848347</td>\n",
       "      <td>0.617762</td>\n",
       "      <td>0.865527</td>\n",
       "      <td>0.628989</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>0.619070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.24</th>\n",
       "      <td>0.827042</td>\n",
       "      <td>0.699132</td>\n",
       "      <td>0.842953</td>\n",
       "      <td>0.656343</td>\n",
       "      <td>0.858730</td>\n",
       "      <td>0.672836</td>\n",
       "      <td>0.789993</td>\n",
       "      <td>0.918653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.818829</td>\n",
       "      <td>0.761269</td>\n",
       "      <td>0.836824</td>\n",
       "      <td>0.694669</td>\n",
       "      <td>0.852390</td>\n",
       "      <td>0.714091</td>\n",
       "      <td>0.789955</td>\n",
       "      <td>0.919376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.26</th>\n",
       "      <td>0.811420</td>\n",
       "      <td>0.816233</td>\n",
       "      <td>0.831523</td>\n",
       "      <td>0.731570</td>\n",
       "      <td>0.845144</td>\n",
       "      <td>0.751868</td>\n",
       "      <td>0.788222</td>\n",
       "      <td>0.945226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.27</th>\n",
       "      <td>0.805245</td>\n",
       "      <td>0.862286</td>\n",
       "      <td>0.825563</td>\n",
       "      <td>0.768814</td>\n",
       "      <td>0.839217</td>\n",
       "      <td>0.787162</td>\n",
       "      <td>0.788222</td>\n",
       "      <td>0.945226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.28</th>\n",
       "      <td>0.800490</td>\n",
       "      <td>0.899392</td>\n",
       "      <td>0.821257</td>\n",
       "      <td>0.800039</td>\n",
       "      <td>0.833236</td>\n",
       "      <td>0.819761</td>\n",
       "      <td>0.786341</td>\n",
       "      <td>0.966766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.29</th>\n",
       "      <td>0.796707</td>\n",
       "      <td>0.927060</td>\n",
       "      <td>0.816984</td>\n",
       "      <td>0.827313</td>\n",
       "      <td>0.827508</td>\n",
       "      <td>0.849328</td>\n",
       "      <td>0.785084</td>\n",
       "      <td>0.979504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>0.793560</td>\n",
       "      <td>0.947592</td>\n",
       "      <td>0.813488</td>\n",
       "      <td>0.851089</td>\n",
       "      <td>0.822356</td>\n",
       "      <td>0.876128</td>\n",
       "      <td>0.785084</td>\n",
       "      <td>0.979504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.31</th>\n",
       "      <td>0.791332</td>\n",
       "      <td>0.962653</td>\n",
       "      <td>0.809961</td>\n",
       "      <td>0.871796</td>\n",
       "      <td>0.817468</td>\n",
       "      <td>0.898566</td>\n",
       "      <td>0.783017</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.32</th>\n",
       "      <td>0.789626</td>\n",
       "      <td>0.973544</td>\n",
       "      <td>0.807135</td>\n",
       "      <td>0.890780</td>\n",
       "      <td>0.813036</td>\n",
       "      <td>0.918280</td>\n",
       "      <td>0.783017</td>\n",
       "      <td>0.999489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.33</th>\n",
       "      <td>0.787975</td>\n",
       "      <td>0.981396</td>\n",
       "      <td>0.804386</td>\n",
       "      <td>0.907470</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.934415</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.34</th>\n",
       "      <td>0.786751</td>\n",
       "      <td>0.986779</td>\n",
       "      <td>0.801752</td>\n",
       "      <td>0.922049</td>\n",
       "      <td>0.805550</td>\n",
       "      <td>0.947870</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.35</th>\n",
       "      <td>0.785795</td>\n",
       "      <td>0.990424</td>\n",
       "      <td>0.799536</td>\n",
       "      <td>0.934773</td>\n",
       "      <td>0.802453</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.36</th>\n",
       "      <td>0.785123</td>\n",
       "      <td>0.992966</td>\n",
       "      <td>0.797465</td>\n",
       "      <td>0.945795</td>\n",
       "      <td>0.799518</td>\n",
       "      <td>0.965948</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.37</th>\n",
       "      <td>0.784554</td>\n",
       "      <td>0.995055</td>\n",
       "      <td>0.795429</td>\n",
       "      <td>0.954495</td>\n",
       "      <td>0.797502</td>\n",
       "      <td>0.973252</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.38</th>\n",
       "      <td>0.784055</td>\n",
       "      <td>0.996231</td>\n",
       "      <td>0.793783</td>\n",
       "      <td>0.962405</td>\n",
       "      <td>0.795294</td>\n",
       "      <td>0.978818</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.39</th>\n",
       "      <td>0.783645</td>\n",
       "      <td>0.997078</td>\n",
       "      <td>0.792381</td>\n",
       "      <td>0.969052</td>\n",
       "      <td>0.793252</td>\n",
       "      <td>0.983310</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>0.783507</td>\n",
       "      <td>0.997619</td>\n",
       "      <td>0.791164</td>\n",
       "      <td>0.974457</td>\n",
       "      <td>0.791909</td>\n",
       "      <td>0.987042</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.41</th>\n",
       "      <td>0.783391</td>\n",
       "      <td>0.997991</td>\n",
       "      <td>0.789981</td>\n",
       "      <td>0.979117</td>\n",
       "      <td>0.790554</td>\n",
       "      <td>0.989949</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.42</th>\n",
       "      <td>0.783321</td>\n",
       "      <td>0.998269</td>\n",
       "      <td>0.788776</td>\n",
       "      <td>0.983171</td>\n",
       "      <td>0.789280</td>\n",
       "      <td>0.992199</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.43</th>\n",
       "      <td>0.783256</td>\n",
       "      <td>0.998568</td>\n",
       "      <td>0.787689</td>\n",
       "      <td>0.986385</td>\n",
       "      <td>0.788273</td>\n",
       "      <td>0.994054</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.44</th>\n",
       "      <td>0.783191</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>0.786897</td>\n",
       "      <td>0.989307</td>\n",
       "      <td>0.787581</td>\n",
       "      <td>0.995362</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.45</th>\n",
       "      <td>0.783170</td>\n",
       "      <td>0.998934</td>\n",
       "      <td>0.786175</td>\n",
       "      <td>0.991805</td>\n",
       "      <td>0.786892</td>\n",
       "      <td>0.996479</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.46</th>\n",
       "      <td>0.783128</td>\n",
       "      <td>0.999007</td>\n",
       "      <td>0.785367</td>\n",
       "      <td>0.994032</td>\n",
       "      <td>0.786293</td>\n",
       "      <td>0.997261</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.47</th>\n",
       "      <td>0.783085</td>\n",
       "      <td>0.999094</td>\n",
       "      <td>0.784731</td>\n",
       "      <td>0.995588</td>\n",
       "      <td>0.785718</td>\n",
       "      <td>0.998006</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.48</th>\n",
       "      <td>0.783068</td>\n",
       "      <td>0.999182</td>\n",
       "      <td>0.784301</td>\n",
       "      <td>0.996940</td>\n",
       "      <td>0.785290</td>\n",
       "      <td>0.998576</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.49</th>\n",
       "      <td>0.783079</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.783946</td>\n",
       "      <td>0.997874</td>\n",
       "      <td>0.784936</td>\n",
       "      <td>0.998985</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.783058</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.783648</td>\n",
       "      <td>0.998554</td>\n",
       "      <td>0.784563</td>\n",
       "      <td>0.999255</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LG_precision_0  LG_recall_0  NN_precision_0  NN_recall_0  \\\n",
       "0.10        0.922065     0.019962        0.916511     0.114421   \n",
       "0.11        0.920825     0.032621        0.909655     0.157384   \n",
       "0.12        0.914194     0.049961        0.903576     0.202670   \n",
       "0.13        0.912105     0.073751        0.898054     0.246116   \n",
       "0.14        0.906909     0.102113        0.894042     0.284733   \n",
       "0.15        0.901266     0.137750        0.888481     0.323555   \n",
       "0.16        0.895616     0.180553        0.883606     0.362312   \n",
       "0.17        0.889522     0.230478        0.878100     0.400089   \n",
       "0.18        0.881427     0.287012        0.872609     0.437238   \n",
       "0.19        0.873323     0.349522        0.867916     0.472518   \n",
       "0.20        0.864312     0.416882        0.862994     0.507571   \n",
       "0.21        0.855109     0.487893        0.858536     0.543340   \n",
       "0.22        0.845183     0.559453        0.853946     0.579992   \n",
       "0.23        0.835914     0.630866        0.848347     0.617762   \n",
       "0.24        0.827042     0.699132        0.842953     0.656343   \n",
       "0.25        0.818829     0.761269        0.836824     0.694669   \n",
       "0.26        0.811420     0.816233        0.831523     0.731570   \n",
       "0.27        0.805245     0.862286        0.825563     0.768814   \n",
       "0.28        0.800490     0.899392        0.821257     0.800039   \n",
       "0.29        0.796707     0.927060        0.816984     0.827313   \n",
       "0.30        0.793560     0.947592        0.813488     0.851089   \n",
       "0.31        0.791332     0.962653        0.809961     0.871796   \n",
       "0.32        0.789626     0.973544        0.807135     0.890780   \n",
       "0.33        0.787975     0.981396        0.804386     0.907470   \n",
       "0.34        0.786751     0.986779        0.801752     0.922049   \n",
       "0.35        0.785795     0.990424        0.799536     0.934773   \n",
       "0.36        0.785123     0.992966        0.797465     0.945795   \n",
       "0.37        0.784554     0.995055        0.795429     0.954495   \n",
       "0.38        0.784055     0.996231        0.793783     0.962405   \n",
       "0.39        0.783645     0.997078        0.792381     0.969052   \n",
       "0.40        0.783507     0.997619        0.791164     0.974457   \n",
       "0.41        0.783391     0.997991        0.789981     0.979117   \n",
       "0.42        0.783321     0.998269        0.788776     0.983171   \n",
       "0.43        0.783256     0.998568        0.787689     0.986385   \n",
       "0.44        0.783191     0.998693        0.786897     0.989307   \n",
       "0.45        0.783170     0.998934        0.786175     0.991805   \n",
       "0.46        0.783128     0.999007        0.785367     0.994032   \n",
       "0.47        0.783085     0.999094        0.784731     0.995588   \n",
       "0.48        0.783068     0.999182        0.784301     0.996940   \n",
       "0.49        0.783079     0.999299        0.783946     0.997874   \n",
       "0.50        0.783058     0.999357        0.783648     0.998554   \n",
       "\n",
       "      XG_precision_0  XG_recall_0  RF_precision_0  RF_recall_0  \n",
       "0.10        0.958821     0.076022        0.000000     0.000000  \n",
       "0.11        0.950664     0.109783        0.000000     0.000000  \n",
       "0.12        0.941746     0.147721        0.000000     0.000000  \n",
       "0.13        0.934364     0.189348        0.889115     0.022373  \n",
       "0.14        0.927592     0.233275        0.889115     0.022373  \n",
       "0.15        0.919831     0.276560        0.873909     0.049004  \n",
       "0.16        0.913495     0.322182        0.867842     0.069741  \n",
       "0.17        0.906762     0.366402        0.854341     0.128869  \n",
       "0.18        0.899981     0.411235        0.852425     0.142352  \n",
       "0.19        0.893790     0.454060        0.842506     0.242646  \n",
       "0.20        0.886708     0.497820        0.836001     0.294185  \n",
       "0.21        0.880041     0.542069        0.829831     0.359112  \n",
       "0.22        0.873208     0.585332        0.823962     0.403522  \n",
       "0.23        0.865527     0.628989        0.806300     0.619070  \n",
       "0.24        0.858730     0.672836        0.789993     0.918653  \n",
       "0.25        0.852390     0.714091        0.789955     0.919376  \n",
       "0.26        0.845144     0.751868        0.788222     0.945226  \n",
       "0.27        0.839217     0.787162        0.788222     0.945226  \n",
       "0.28        0.833236     0.819761        0.786341     0.966766  \n",
       "0.29        0.827508     0.849328        0.785084     0.979504  \n",
       "0.30        0.822356     0.876128        0.785084     0.979504  \n",
       "0.31        0.817468     0.898566        0.783017     0.999489  \n",
       "0.32        0.813036     0.918280        0.783017     0.999489  \n",
       "0.33        0.809200     0.934415        0.782930     1.000000  \n",
       "0.34        0.805550     0.947870        0.782930     1.000000  \n",
       "0.35        0.802453     0.957877        0.782930     1.000000  \n",
       "0.36        0.799518     0.965948        0.782930     1.000000  \n",
       "0.37        0.797502     0.973252        0.782930     1.000000  \n",
       "0.38        0.795294     0.978818        0.782930     1.000000  \n",
       "0.39        0.793252     0.983310        0.782930     1.000000  \n",
       "0.40        0.791909     0.987042        0.782930     1.000000  \n",
       "0.41        0.790554     0.989949        0.782930     1.000000  \n",
       "0.42        0.789280     0.992199        0.782930     1.000000  \n",
       "0.43        0.788273     0.994054        0.782930     1.000000  \n",
       "0.44        0.787581     0.995362        0.782930     1.000000  \n",
       "0.45        0.786892     0.996479        0.782930     1.000000  \n",
       "0.46        0.786293     0.997261        0.782930     1.000000  \n",
       "0.47        0.785718     0.998006        0.782930     1.000000  \n",
       "0.48        0.785290     0.998576        0.782930     1.000000  \n",
       "0.49        0.784936     0.998985        0.782930     1.000000  \n",
       "0.50        0.784563     0.999255        0.782930     1.000000  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_0=pd.DataFrame({'LG_precision_0':lg_precision_0, 'LG_recall_0': lg_recall_0,\\\n",
    "                 'NN_precision_0':nn_precision_0,'NN_recall_0':nn_recall_0,\\\n",
    "                 'XG_precision_0':xg_precision_0,'XG_recall_0':xg_recall_0,\\\n",
    "                 'RF_precision_0':rf_precision_0,'RF_recall_0':rf_recall_0},index=thresholds)\n",
    "class_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0512fc",
   "metadata": {},
   "source": [
    ">It depends on the business's risk tolerance that the approriate threshold should be chosen. However, at threshold **0.2** in **random forest** model, precision and recall for both classes look quite balanced. Therefore, I would choose this threshold for classifying this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcdb312",
   "metadata": {},
   "source": [
    "### Scoring test set - Random Forest - Threshold 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "38dc1112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======TEST======\n",
      "Class 0 - Precision:  0.8361\n",
      "Class 0 - Recall:  0.298\n",
      "\n",
      "Class 1 - Precision:  0.2377\n",
      "Class 1 - Recall:  0.7894\n"
     ]
    }
   ],
   "source": [
    "rf_precision_1 = []\n",
    "rf_recall_1 = []\n",
    "rf_precision_0 = []\n",
    "rf_recall_0 = []\n",
    "\n",
    "rf_y_proba_test=rf_fitted.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Apply threshold\n",
    "y_threshold = np.where(rf_y_proba_test >= 0.2, 1, 0)\n",
    "rf_report=classification_report(y_test, y_threshold,output_dict=True)\n",
    "\n",
    "print('======TEST======')\n",
    "print('Class 0 - Precision: ', np.round(rf_report['0']['precision'],4))\n",
    "print('Class 0 - Recall: ', np.round(rf_report['0']['recall'],4))\n",
    "\n",
    "print('\\nClass 1 - Precision: ',np.round(rf_report['1']['precision'],4))\n",
    "print('Class 1 - Recall: ',np.round(rf_report['1']['recall'],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150f37d",
   "metadata": {},
   "source": [
    "# Feature Selection <a class=\"anchor\" id=\"fs\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "962947b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy=X_train.drop(columns=['EMPLOYMENT_TYPE','PERFORM_CNS_SCORE_DESCRIPTION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c92a55c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 5 features were selected =====\n",
      "DISBURSED_AMOUNT, LTV, STATE_ID, PERFORM_CNS_SCORE, CREDIT_HISTORY_LENGTH\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "kbest = SelectKBest(f_regression, k=5).fit(X_train_copy, y_train)\n",
    "\n",
    "# See selected features\n",
    "kbest_features = X_train_copy.columns[kbest.get_support()]\n",
    "\n",
    "print(f\"===== {len(kbest_features)} features were selected =====\")\n",
    "print(f\"{', '.join(kbest_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "123dbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_5=X_train[['DISBURSED_AMOUNT', 'LTV', 'STATE_ID', 'PERFORM_CNS_SCORE', 'CREDIT_HISTORY_LENGTH']]\n",
    "\n",
    "X_test_5=X_test[['DISBURSED_AMOUNT', 'LTV', 'STATE_ID', 'PERFORM_CNS_SCORE', 'CREDIT_HISTORY_LENGTH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d5034e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=35,\n",
       "                       random_state=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=35,\n",
       "                       random_state=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=35,\n",
       "                       random_state=100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate and fit the chosen classifier\n",
    "rf_new = RandomForestClassifier(n_estimators=35, min_samples_leaf=3, max_depth=10, random_state=100)\n",
    "rf_new.fit(X_train_5,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42a8a9ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829468447087753"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train score\n",
    "rf_new.score(X_train_5,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10040da2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7829264526754619"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test score\n",
    "rf_new.score(X_test_5,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24e2f2",
   "metadata": {},
   "source": [
    "We see that these 5 features produced the same accuracy **~0.783** with the original 40 ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d54976dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======TRAIN======\n",
      "Class 0 - Precision:  0.8843\n",
      "Class 0 - Recall:  0.4845\n",
      "\n",
      "Class 1 - Precision:  0.2932\n",
      "Class 1 - Recall:  0.7713\n"
     ]
    }
   ],
   "source": [
    "rf_y_proba_train=rf_new.predict_proba(X_train_5)[:, 1]\n",
    "\n",
    "# Apply threshold\n",
    "y_threshold = np.where(rf_y_proba_train >= 0.2, 1, 0)\n",
    "rf_report=classification_report(y_train, y_threshold,output_dict=True)\n",
    "\n",
    "print('======TRAIN======')\n",
    "print('Class 0 - Precision: ', np.round(rf_report['0']['precision'],4))\n",
    "print('Class 0 - Recall: ', np.round(rf_report['0']['recall'],4))\n",
    "\n",
    "print('\\nClass 1 - Precision: ',np.round(rf_report['1']['precision'],4))\n",
    "print('Class 1 - Recall: ',np.round(rf_report['1']['recall'],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5501f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======TEST======\n",
      "Class 0 - Precision:  0.8556\n",
      "Class 0 - Recall:  0.4666\n",
      "\n",
      "Class 1 - Precision:  0.2712\n",
      "Class 1 - Recall:  0.7159\n"
     ]
    }
   ],
   "source": [
    "rf_y_proba_test=rf_new.predict_proba(X_test_5)[:, 1]\n",
    "\n",
    "# Apply threshold\n",
    "y_threshold = np.where(rf_y_proba_test >= 0.2, 1, 0)\n",
    "rf_report=classification_report(y_test, y_threshold,output_dict=True)\n",
    "\n",
    "print('======TEST======')\n",
    "print('Class 0 - Precision: ', np.round(rf_report['0']['precision'],4))\n",
    "print('Class 0 - Recall: ', np.round(rf_report['0']['recall'],4))\n",
    "\n",
    "print('\\nClass 1 - Precision: ',np.round(rf_report['1']['precision'],4))\n",
    "print('Class 1 - Recall: ',np.round(rf_report['1']['recall'],4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensemble",
   "language": "python",
   "name": "ensemble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
